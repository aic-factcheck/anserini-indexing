#!/bin/bash
#SBATCH --time=04:00:00
#SBATCH --nodes=1 --ntasks-per-node=1 --cpus-per-task=4
#SBATCH --mem=32G
#SBATCH --partition=cpufast
#SBATCH --job-name anserini_wiki_retrieval
#SBATCH --out=../logs/anserini_wiki_retrieval.%j.out

source wiki_en_20230801_env.sh
# source enfever_over_wiki_en_20230801_env.sh

mkdir -p ${RETRIEVAL}
mkdir -p ${ROOT}/predictions

# Generate queries and qrels files for the dev split = side-step needed by anserini
echo "--------------- generate_queries_and_qrels ---------------"
python src/generate_queries_and_qrels.py \
    --dataset_file ${DEV} \
    --output_queries_file ${RETRIEVAL}/queries.${SPLIT}.tsv \
    --output_qrels_file ${RETRIEVAL}/qrels.${SPLIT}.tsv \
    --granularity paragraph

# Retrieval run
echo "--------------- retrieve ---------------"
python src/retrieve.py \
    --hits 500 --threads 1 \
    --index ${INDEX} \
    --queries ${RETRIEVAL}/queries.${SPLIT}.tsv \
    --output ${RETRIEVAL}/predicted.${SPLIT}.tsv \
    --k1 ${k1} --b ${b}  # BEST HYPERPARAMETERS: CTK 0.6 0.5 | FEVER 0.9 0.9 1.2 0.5

# Evaluate
# echo "--------------- evaluate_doc_retrieval ---------------"
# python src/evaluate_doc_retrieval.py \
#     --truth_file ${DEV} \
#     --run_file ${RETRIEVAL}/predicted.${SPLIT}.tsv \
#     --evidence_level doc

# Prepare predictions file for DR evaluation
echo "--------------- generate_predictions ---------------"
python src/generate_predictions.py \
    --original_dev ${DEV} \
    --predictions ${PREDICTIONS} \
    --output ${OUTPUT} \